{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science 101\n",
    "\n",
    "<i>House Price practical -- Introduction to Data Science</i>\n",
    "\n",
    "In this practical, you will familiarize yourself with data exploration, visualization and analysis techniques using Python. It will take you through the basics of several key steps in the data science process. Running the cell below imports the necessary modules and functions, which we will use throughout the rest of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary modules and functions\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 16, 8\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Exploration: Correlation and Visualization\n",
    "\n",
    "You will investigate a dataset listing several features of houses, including their sale price.\n",
    "\n",
    "After getting a feel for the information these features contain, you will use a simple regression model to predict this sale price. Begin by importing the data from the provided CSV file. Refer to your cheatsheet for the correct syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the 'HousePrices.csv' file into a Pandas DataFrame.\n",
    "# Hint: First inspect the file to find what delimiter it uses!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As is commonly the case with data of this nature, rows represent observations (houses) and columns represent the features in terms of which they are described.\n",
    "\n",
    "Use the next two cells to <i>i)</i> print the names of the dataset's features and <i>ii)</i> print the first 10 rows. As before, refer to your cheatsheet for syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the imported dataframe's column headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the dataframe's first 10 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some, but not all column names are self-explanatory. For the sake of clarity, we provide each feature's description below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    SalePrice - the property's sale price in dollars. This is the target variable that you're trying to predict.\n",
    "    MSSubClass: The building class\n",
    "    MSZoning: The general zoning classification\n",
    "    LotFrontage: Linear feet of street connected to property\n",
    "    LotArea: Lot size in square feet\n",
    "    Street: Type of road access\n",
    "    Alley: Type of alley access\n",
    "    LotShape: General shape of property\n",
    "    LandContour: Flatness of the property\n",
    "    Utilities: Type of utilities available\n",
    "    LotConfig: Lot configuration\n",
    "    LandSlope: Slope of property\n",
    "    Neighborhood: Physical locations within Ames city limits\n",
    "    Condition1: Proximity to main road or railroad\n",
    "    Condition2: Proximity to main road or railroad (if a second is present)\n",
    "    BldgType: Type of dwelling\n",
    "    HouseStyle: Style of dwelling\n",
    "    OverallQual: Overall material and finish quality\n",
    "    OverallCond: Overall condition rating\n",
    "    YearBuilt: Original construction date\n",
    "    YearRemodAdd: Remodel date\n",
    "    RoofStyle: Type of roof\n",
    "    RoofMatl: Roof material\n",
    "    Exterior1st: Exterior covering on house\n",
    "    Exterior2nd: Exterior covering on house (if more than one material)\n",
    "    MasVnrType: Masonry veneer type\n",
    "    MasVnrArea: Masonry veneer area in square feet\n",
    "    ExterQual: Exterior material quality\n",
    "    ExterCond: Present condition of the material on the exterior\n",
    "    Foundation: Type of foundation\n",
    "    BsmtQual: Height of the basement\n",
    "    BsmtCond: General condition of the basement\n",
    "    BsmtExposure: Walkout or garden level basement walls\n",
    "    BsmtFinType1: Quality of basement finished area\n",
    "    BsmtFinSF1: Type 1 finished square feet\n",
    "    BsmtFinType2: Quality of second finished area (if present)\n",
    "    BsmtFinSF2: Type 2 finished square feet\n",
    "    BsmtUnfSF: Unfinished square feet of basement area\n",
    "    TotalBsmtSF: Total square feet of basement area\n",
    "    Heating: Type of heating\n",
    "    HeatingQC: Heating quality and condition\n",
    "    CentralAir: Central air conditioning\n",
    "    Electrical: Electrical system\n",
    "    1stFlrSF: First Floor square feet\n",
    "    2ndFlrSF: Second floor square feet\n",
    "    LowQualFinSF: Low quality finished square feet (all floors)\n",
    "    GrLivArea: Above grade (ground) living area square feet\n",
    "    BsmtFullBath: Basement full bathrooms\n",
    "    BsmtHalfBath: Basement half bathrooms\n",
    "    FullBath: Full bathrooms above grade\n",
    "    HalfBath: Half baths above grade\n",
    "    Bedroom: Number of bedrooms above basement level\n",
    "    Kitchen: Number of kitchens\n",
    "    KitchenQual: Kitchen quality\n",
    "    TotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\n",
    "    Functional: Home functionality rating\n",
    "    Fireplaces: Number of fireplaces\n",
    "    FireplaceQu: Fireplace quality\n",
    "    GarageType: Garage location\n",
    "    GarageYrBlt: Year garage was built\n",
    "    GarageFinish: Interior finish of the garage\n",
    "    GarageCars: Size of garage in car capacity\n",
    "    GarageArea: Size of garage in square feet\n",
    "    GarageQual: Garage quality\n",
    "    GarageCond: Garage condition\n",
    "    PavedDrive: Paved driveway\n",
    "    WoodDeckSF: Wood deck area in square feet\n",
    "    OpenPorchSF: Open porch area in square feet\n",
    "    EnclosedPorch: Enclosed porch area in square feet\n",
    "    3SsnPorch: Three season porch area in square feet\n",
    "    ScreenPorch: Screen porch area in square feet\n",
    "    PoolArea: Pool area in square feet\n",
    "    PoolQC: Pool quality\n",
    "    Fence: Fence quality\n",
    "    MiscFeature: Miscellaneous feature not covered in other categories\n",
    "    MiscVal: Value of miscellaneous feature\n",
    "    MoSold: Month Sold\n",
    "    YrSold: Year Sold\n",
    "    SaleType: Type of sale\n",
    "    SaleCondition: Condition of sale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>SalePrice</i> is our main feature of interest. Use the <b>.describe()</b> method to print a table summarizing some key statistics of the distribution of these prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the distribution of sale prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do these numbers represent? Briefly describe what the value in each row indicates in the cell below.\n",
    "\n",
    "<i>Note: The next cell is a <u>Markdown</u> cell, which Jupyter interprets as (formatted) text instead of executable Python code!</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***\n",
    "```\n",
    "Answer:\n",
    "\n",
    "\n",
    "```\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more intuitive way to summarize the sale prices in our dataset, is to visualize their distribution in a plot. The Seaborn module we imported at the start of this notebook (<b>import seaborn as sns</b>) has a function that does just that. Use your cheatsheet to find it, and run it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of the SalePrice data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the distribution clearly is <b>not</b> normal; it leans left, also called \"right skewed.\"\n",
    "\n",
    "Carefully examine the list of features this dataset contains. Choose two quantitative features (that is, not qualitative / categorical) which you suspect correlate with <i>SalePrice</i>. Make two scatter plots, to visualize whether or not there is indeed a correlation between the sale price and your chosen features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot SalePrice versus two other quantitative features, in separate scatter plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe your produced graphs. What stands out? Do your chosen features seem to have any predictive power for <i>SalePrice</i>? Is the relationship positive? Linear? Monotonic?\n",
    "\n",
    "<i>Note: The next cell is a <u>Markdown</u> cell again!</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "```\n",
    "Answer:\n",
    "\n",
    "\n",
    "```\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scatter plots are just one of many ways to visualize whether or not correlation exists between two variables. \n",
    "\n",
    "Combine the dataframe's <b>.corr()</b> method to calculate correlation coefficients between specified columns (<i>SalePrice</i> and the two variables you selected), with the <b>heatmap()</b> function from Seaborn to plot a correlation matrix.\n",
    "\n",
    "<i>Bonus question: What does the chosen correlation method assume about the distribution of its input variables? What other methods does <b>.corr()</b> provide, and when are these appropriate to use?</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# cols = ['SalePrice', ...]\n",
    "# corrmat = ... .corr()\n",
    "# sns.heatmap(corrmat, square=True, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, choose a categorical (qualitative) variable, either nominal or ordinal, which you suspect influences a house's sale price.\n",
    "\n",
    "Instead of a scatter plot, box-and-whisker plots can be insightful to visualize a quantitative variable's distribution versus individual categories of a categorical variable. Create and describe such a boxplot for <i>SalePrice</i> versus your chosen variable in the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boxplot for your chosen variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your variable spans too many categories, the plot above may have turned into a gigantic, illegible rainbow. Consider rerunning the previous cell with a different variable if this is the case.\n",
    "\n",
    "What do the boxes, whiskers, centerlines and dots represent? Is there a convincing pattern relating the categories to <i>SalePrice</i>?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***\n",
    "```\n",
    "Answer:\n",
    "\n",
    "\n",
    "```\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to scale things up. Create a correlation matrix for the <i>entire</i> dataset, and visualize it with a heatmap as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a heatmap of the correlation matrix for your entire dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carefully study your correlation matrix.\n",
    "\n",
    "Choose a variable that doesn't seem to correlate with anything. Can you explain why not?\n",
    "\n",
    "The heatmap has fewer rows and columns than there are features in your dataset. Which features are missing? Why?\n",
    "\n",
    "<i>Bonus question: Seaborn provides a function that clusters rows and columns of your correlation matrix together. Find the function that does this instead of <b>heatmap()</b>, and rerun the previous cell. Identify some of the pairs of features that strongly correlate, and explain why you think this does or does not make sense.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***\n",
    "```\n",
    "Answer:\n",
    "\n",
    "\n",
    "```\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoom in on the 10 features which most strongly correlate with <i>SalePrice</i>. Include the correlation coefficients between every pair of features in your heatmap using annotations.\n",
    "\n",
    "Hint: Look up the <i>annot</i>, <i>fmt</i> and <i>annot_kws</i> keyword arguments for the <b>heatmap()</b> function in the online Seaborn documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap for the 10 features which best correlate with SalePrice\n",
    "# cols = corrmat.nlargest(10, 'SalePrice').index\n",
    "# sns.heatmap(corrmat.loc[cols,cols], ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, several of the top features are strongly correlated (coefficient > 0.8) with each other, not just <i>SalePrice</i>:\n",
    "* The number of cars that fit into a garrage is correlated with said garage's surface area\n",
    "* The number of rooms above ground correlates with the livable surface area above ground\n",
    "* The basement's surface area correlates tightly with the 1st floor's\n",
    "\n",
    "The correlation isn't perfect, but there's still a lot of redundant information in these pairs. Thus, for the sake of this exercise, we will continue our analysis with the following features:\n",
    "    \n",
    "    SalePrice, OverallQual, GrLivArea, GarageCars, TotalBsmtSF, FullBath, YearBuilt\n",
    "\n",
    "# Digging Deeper: Missing Data and Outlier Detection\n",
    "\n",
    "Investigate if there are any missing values in the listed features, by chaining the <b>.isnull()</b> and <b>.sum()</b> dataframe methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many entries are missing for the selected features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null values can be safely ignored or huge hindrances, depending on the type of analysis you're performing.\n",
    "\n",
    "We will perform Ordinary Least Squares (OLS) Regression later on, which would be hindered by missing data. Thus, we're going to try and estimate how many cars fit in each garage, filling in the null values.\n",
    "\n",
    "We know <i>GarageCars</i> correlates with another variable. How would you use this correlation to estimate the missing values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***\n",
    "```\n",
    "Answer:\n",
    "\n",
    "```\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect what value <i>GarageArea</i> has for different amounts of <i>GarageCars</i> in a manner you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the distribution of <i>GarageArea</i> for which <i>GarageCars</i> is null?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the distributions of <i>GarageArea</i> between the houses with known versus unknown <i>GarageCars</i>. Think of a way to estimate one from the other, implement and explain it, and fill in the missing values in your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the missing GarageCars values in df_houseprices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm there are no more missing values for <i>GarageCars</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data might also contain outliers. Not all methods are equally susceptible to outliers, but it's important to identify them nonetheless. In general, removing outliers from data will improve the performance of models trained on said data.\n",
    "\n",
    "Scatter plot <i>SalePrice</i> against <i>GrLivArea</i> and see for yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The four points with the highest <i>GrLivArea</i> appear to be isolated, compared to the rest of the feature's values. Two look like they might be outliers. Which ones, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***\n",
    "```\n",
    "Answer:\n",
    "\n",
    "\n",
    "```\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Print all available data for the two possible outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does anything stand out to explain why these houses are outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***\n",
    "```\n",
    "Answer:\n",
    "\n",
    "\n",
    "```\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll want to remove these houses from our dataset before training any models, so <b>.drop()</b> them from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_drop = df_houseprices.index[df_houseprices['GrLivArea'] > ...]\n",
    "# df_houseprices.drop(to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the steps you've taken for <i>TotalBsmtSF</i>.\n",
    "1. Make a scatterplot,\n",
    "2. investigate possible outliers, and\n",
    "3. decide whether or not to drop the points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Towards Testing: Data Transformation and Feature Derivation\n",
    "\n",
    "Before we go any further, you should know the basics of four key concepts, assumptions about which having significant consequences to whether or not certain statistical methods are appropriate to apply. The book [Multivariate Data Analysis](https://www.amazon.com/Multivariate-Data-Analysis-Joseph-Hair/dp/9332536503) by Hair et al. introduces them as follows:\n",
    "\n",
    "* <b>Normality</b> - When we talk about normality, we mean that the data should follow a normal, Gaussian distribution: the characteristic \"bell curve.\" Many statistical analyses (e.g. t-tests, ANOVA, simple regression) assume a normal distribution, so in case the data follows a different one, they must be transformed, or analysed with methods appropriate for the observed distribution.<br><br>\n",
    "\n",
    "* <b>Homoscedasticity</b> - Homoscedasticity refers to the 'assumption that dependent variable(s) exhibit equal levels of variance across the range of predictor variable(s)' [(Hair et al., 2013)](https://www.amazon.com/Multivariate-Data-Analysis-Joseph-Hair/dp/9332536503). In other words, the variance (and standard deviation) should be equivalent across your features. If this is not the case (i.e. the data is <i>hetero</i>scedastic), mathematical and computational treatment of the data becomes much trickier. Failing to notice your data is heteroscedastic can cause you to overestimate the <i>goodness of fit</i> of a model, e.g. Pearson's correlation coefficient.<br><br>\n",
    "\n",
    "* <b>Linearity</b> - A common way to assess linearity is to examine scatter plots and search for linear patterns visually. If patterns are not linear, it is worth considering data transformation, or non-parametric testing. The scatter plots we've seen thusfar appear to have mostly linear relationships, so we'll not pay it further attention.<br><br>\n",
    "\n",
    "* <b>Absence of correlated errors</b> - Linear regression models, along with many other statistical methods, explicitly assume that errors are independent. Correlated errors, like the name suggests, break this assumption. Autocorrelation most often occurs in time series data, but should not be an issue here.<br><br>\n",
    "\n",
    "At the start of this notebook, you made a distribution plot for <i>SalePrice</i>. Produce the same plot in the next cell, but add a normal distribution fitted to the data along with it.\n",
    "\n",
    "Hint: Use the <i>fit</i> keyword argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a distribution plot for SalePrice with a fitted normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A different way of visualizing how well data follows a normal distribution, is through a probability plot. Draw one for <i>SalePrice</i>. Refer to your cheatsheet for the correct syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The theoretical quantiles are distributed in such a way, that if the data is normally distributed, it will follow the red line. Does <i>SalePrice</i> look to follow a normal distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***\n",
    "```\n",
    "Answer:\n",
    "\n",
    "\n",
    "```\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive (right) skew can sometimes be solved by log-transforming data. Add a column <i>LogSalePrice</i> with log-transformed prices to your dataframe and draw a new distribution plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_houseprices['LogSalePrice'] = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also draw the probability plot of your log-transformed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all went well, your new feature should now be normally distributed, which is one of the assumptions of the statistical method we want to apply.\n",
    "\n",
    "Repeat this process for two more of our quantitative variables: <i>GrLivArea</i> and <i>TotalBsmtSF</i>.\n",
    "\n",
    "First, draw a probability plot for <i>GrLivArea</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a probability plot for GrLivArea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We appear to be dealing with more positive skew. As before, add a log-transformed column <i>LogGrLivArea</i> to your dataframe and redraw the probability plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a probability plot for LogGrLivArea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is immediately obvious the log-transformed values follow the normal distribution more nicely than the untransformed ones. Try again, this time with <i>TotalBsmtSF</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a probability plot for TotalBsmtSF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do we see the same thing happening here, or is something else going on?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***\n",
    "```\n",
    "Answer:\n",
    "\n",
    "```\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Log(0)</i> does not exist, so log-transformation will not fix this. We'll try something else.\n",
    "\n",
    "One possible solution is to collapse our quantitative feature into a qualitative one, e.g. categorizing it into basements that are absent / small / medium / large. Even simpler would be to classify if a house does or does not have a basement at all.\n",
    "\n",
    "Draw a distribution plot for <i>TotalBsmtSF</i> to help decide which of these options makes more sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside from the basements with a surface area of 0, there is only one clear peak in the distribution (albeit with a shoulder). Declaring arbitrary thresholds for size categories makes little sense here, so we'll add a boolean feature to describe whether or not a house has a basement at all.\n",
    "\n",
    "Add such a column to your dataframe, with the label <i>HasBsmt</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_houseprices['HasBsmt'] = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should check how our new feature relates to our sale prices. <i>HasBsmt</i> is categorical, so a boxplot is appropriate.\n",
    "\n",
    "Should we use <i>SalePrice</i> or <i>LogSalePrice</i> on the y axis? Explain why in a comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does having a basement correlate with sale price? Is there enough difference between the categories?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***\n",
    "```\n",
    "Answer:\n",
    "\n",
    "```\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An added benefit of normalizing our data with log-transformation, is that it's gotten rid of some heteroscedasticity.\n",
    "\n",
    "Draw two scatter plots: \n",
    "1. <i>GrLivingArea</i> vs. <i>SalePrice</i>\n",
    "2. <i>LogGrLivingArea</i> vs. <i>LogSalePrice</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the two scatter plots to one another. What stands out to you? How would you describe the shape of the clouds?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***\n",
    "```\n",
    "Answer:\n",
    "\n",
    "\n",
    "```\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the point density of the first cloud is inversely proportional to the distance along the axes: the cloud gets thinner at high values, and the average distance to an imaginary trendline increases. This indicates the plotted features are <i>not</i> homoscedastic, unlike the manner in which points are distributed in the log-transformed plot. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Putting it all Together: Training a Regression Model\n",
    "\n",
    "Combining everything we know about the features we've investigated, transformed and derived, with respect to their relation to a house's sale price, we are now going to train an Ordinary Least Squares (OLS) regression model to predict these prices.\n",
    "\n",
    "Running the next cell will split the relevant columns of your dataframe into a training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['OverallQual','LogGrLivArea','GarageCars','FullBath','YearBuilt','HasBsmt']\n",
    "\n",
    "X = df_houseprices[features]\n",
    "y = df_houseprices['LogSalePrice']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # Train:Test = 70%:30%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a LinearRegression model object, fit the training data to it, and print the model's performance score on the training data. Refer to your cheatsheet for the correct syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and fit a linear regression model, then print its score\n",
    "\n",
    "# model = LinearRegression()\n",
    "# model.fit(...)\n",
    "# print model.score(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For regression models, the <b>.score()</b> method returns the coefficient of determination, also known as 'R squared' (R²). It reflects the proportion of variance explained by your model. For example, an R² of 0.80 means our model explains 80% of the variance in <i>LogSalePrice</i>.\n",
    "\n",
    "Also check the model's R² for the <i>test</i> set. Do you expect it to be better, worse, or unchanged compared to the performance on training data? Why?\n",
    "\n",
    "<i>Bonus question: rerunning the previous two cells will cause the score to change slightly. Why?</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, lets visualize what this R² really means.\n",
    "\n",
    "Use the <b>.predict()</b> method to add a column labeled <i>LogPredSalePrice</i> to your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_houseprices['LogPredSalePrice'] = model.predict(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will plot your predicted prices versus the actual ones, with a red line on the diagonal. The closer the points are to the line, the better your predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_houseprices.plot.scatter(x='LogPredSalePrice',y='LogSalePrice')\n",
    "plt.plot([10,14],[10,14],'r')\n",
    "plt.axis([10,14,10,14])\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to this scatter plot, let's plot a distribution of the errors. Subtract <i>LogSalePrice</i> from <i>LogPredSalePrice</i> and visualize the result as you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, add a column </i>PredSalePrice</i> to your dataframe.\n",
    "\n",
    "Take the exponent of your predicted sale prices to undo taking the logarithm, and scatter plot it against the original <i>SalePrice</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freeform Exercise\n",
    "\n",
    "An R² of approximately 0.80 is nothing to sneeze at, but as should be evident from the plot above, there is still plenty of room for improvement. We've given you this exercise as a framework to explore the basics, but now that you're familiar with these first steps, you have the tools necessary to explore further on your own. Add cells to this notebook to improve your analysis of the data, refine your model, and see if you can get better predictions. To get you started:\n",
    "\n",
    "Did you notice the 3 points on the far end of <i>TotalBsmtSF</i> that look like they might be outliers?\n",
    "\n",
    "Use `zip(features, model.coef_)` to inspect the coefficients each feature is assigned by the regression model. Do these weights make sense to you? Do they agree with the correlation coefficients based on which we originally selected them?\n",
    "\n",
    "Consider adding or removing other features from the dataset to the set you train your model on, or transforming/normalizing them.\n",
    "\n",
    "Perhaps try a completely different model.\n",
    "\n",
    "Explore!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credits\n",
    "\n",
    "Adapted by Bas Stringer from material provided by [Scamander](https://www.scamander.com), in turn derived from Pedro Marcelino's [Kaggle kernel](https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python). Original data from ([De Cock, 2011](https://ww2.amstat.org/publications/jse/v19n3/decock.pdf))."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
